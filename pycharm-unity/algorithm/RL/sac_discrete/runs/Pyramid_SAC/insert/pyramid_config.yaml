#behaviors:
#  BehaviorSAC:
#    trainer_type: sac
#    hyperparameters:
#      # 一次抽取多少条数据进行训练
#      batch_size: 1024
#      # 经验池大小
#      buffer_size: 10240
#      # 学习率
#      learning_rate: 3.0e-4
#      # 学习率是Linear则线性递减，达到训练的最大步数衰减为，如果设为Constant则恒定
#      learning_rate_schedule: linear
#      # SAC-specific hyperparameters
#      # Replaces the "PPO-specific hyperparameters" section above
#      buffer_init_steps: 0
#      tau: 0.005
#      steps_per_update: 10.0
#      save_replay_buffer: false
#      init_entcoef: 0.5
#      reward_signal_steps_per_update: 10.0
#
#    network_settings:
#      # 可视化观察的编码类型，simple对应两层卷积神经网络，nature_cnn是三个卷积层，resnet是叠的复杂卷积层
#      vis_encode_type: simple
#      # 是否自动标准化观测值
#      normalize: false
#      # 隐藏层神经网络单元个数
#      hidden_units: 128
#      # 隐藏层层数
#      num_layers: 3
#      # 循环神经网络，注意：LSTM不适用于连续动作，离散动作可以获得更好的结果
#      memory:
#      # 需要记住的经验序列长度，越大记忆越久
#      sequence_length: 64
#      # 智能体保存的记忆大小，必须是2的倍数，且应与期望agent完成任务所需记住的信息量成正比
#      memo  ry_size: 256
#
#    # Trainer configurations common to all trainers
#    # 最大训练步数，达到后自动退出
#    max_steps: 5.0e5
#    # 在添加到经验池之前智能体要经过的步数，如果有频繁的奖励，可以设的小一些
#    time_horizon: 64
#    # 每经过多少步数在面板上显示统计数据
#    summary_freq: 10000
#    # 训练中保留模型的数量
#    keep_checkpoints: 5
#    # 每收集多少经验数据保存一个模型数据，所有保留的模型都会以.onnx文件的形式保存
#    checkpoint_interval: 50000
#    # 允许环境在更新模型时运行，当使用SAC时设为True有利于加速训练，但用Self Play时应设为False
#    threaded: false
#    # 之前保存的模型路径
#    init_path: null

#    # behavior cloning
#    behavioral_cloning:
#      demo_path: E:\705(3)\Paper\experience\ml-agents-develop\Project\Assets\ML-Agents\Examples\Pyramids\Demos\ExpertPyramid.demo
#      strength: 0.5
#      steps: 150000
#      batch_size: 512
#      num_epoch: 3
#      samples_per_update: 0
#
#    reward_signals:
#      # environment reward (default)
#      extrinsic:
#        strength: 1.0
#        gamma: 0.99
#
#      # curiosity module
#      curiosity:
#        strength: 0.02
#        gamma: 0.99
#        encoding_size: 256
#        learning_rate: 3.0e-4




